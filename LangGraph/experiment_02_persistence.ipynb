{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441347a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52df57d3",
   "metadata": {},
   "source": [
    "LangGraph has a built-in persistence layer, implemented through checkpointers. When you compile a graph with a checkpointer, the checkpointer saves a `checkpoint` of the graph state at every super-step. Those checkpoints are saved to a `thread`, which can be accessed after graph execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b3cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e592f452",
   "metadata": {},
   "source": [
    "# Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda470d1",
   "metadata": {},
   "source": [
    "A thread is a unique ID or thread identifier assigned to each checkpoint saved by a checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46661b",
   "metadata": {},
   "source": [
    "When invoking a graph with a checkpointer, you must specify a thread_id as part of the configurable portion of the config.\n",
    "```Python\n",
    "{\"configurable\": {\"thread_id\": \"1\"}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324d15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f683264",
   "metadata": {},
   "source": [
    "# Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78899661",
   "metadata": {},
   "source": [
    "The state of a thread at a particular point in time is called a checkpoint. Checkpoint is a snapshot of the graph state saved at each super-step and is represented by `StateSnapshot` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e762e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(node_a)\n",
    "workflow.add_node(node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca5c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2ca08b4",
   "metadata": {},
   "source": [
    "## Get state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19fa5f",
   "metadata": {},
   "source": [
    "View the latest state of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19087d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-6952-6754-8002-fb1105b5d78b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-04T08:28:17.249053+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-6951-6020-8001-4702b2ed714f'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9133a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd35583d",
   "metadata": {},
   "source": [
    "## Get state history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02aea1",
   "metadata": {},
   "source": [
    "get the full history of the graph execution for a given thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d544b34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-6952-6754-8002-fb1105b5d78b'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-11-04T08:28:17.249053+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-6951-6020-8001-4702b2ed714f'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-6951-6020-8001-4702b2ed714f'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-11-04T08:28:17.248458+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-694e-624e-8000-5cb03659d424'}}, tasks=(PregelTask(id='0a384303-18ae-1496-7fb7-a92945ad1f8a', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-694e-624e-8000-5cb03659d424'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-11-04T08:28:17.247282+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-694b-6bca-bfff-f9a2c2b8c37b'}}, tasks=(PregelTask(id='e29d72d5-806c-9aa9-995a-a67791bb4652', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),), interrupts=()),\n",
       " StateSnapshot(values={'bar': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0b9583-694b-6bca-bfff-f9a2c2b8c37b'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-11-04T08:28:17.246298+00:00', parent_config=None, tasks=(PregelTask(id='a962c6bb-d26e-311d-1799-248208b19692', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'foo': ''}),), interrupts=())]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b74cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77189e29",
   "metadata": {},
   "source": [
    "## Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a10a7",
   "metadata": {},
   "source": [
    "If we invoke a graph with a `thread_id` and a `checkpoint_id`, then we will re-play the previously executed steps before a checkpoint that corresponds to the checkpoint_id, and only execute the steps after the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58cd643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f0b9583-694e-624e-8000-5cb03659d424\"}}\n",
    "graph.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a64d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e58a524",
   "metadata": {},
   "source": [
    "## Update state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb774a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d9b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba9a2cb",
   "metadata": {},
   "source": [
    "# Memory Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8b5ce",
   "metadata": {},
   "source": [
    "Consider the case of a chatbot where we want to retain specific information about the user across all chat conversations (e.g., threads) with that user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758bf69",
   "metadata": {},
   "source": [
    "With checkpointers alone, we cannot share information across threads. This motivates the need for the `Store` interface. As an illustration, we can define an `InMemoryStore` to store information about a user across threads. We simply compile our graph with a checkpointer, as before, and with our new `in_memory_store` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93eb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f5684b",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b78151fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713cbf6",
   "metadata": {},
   "source": [
    "Memories are namespaced by a `tuple`, which in this specific example will be `(<user_id>, \"memories\")`. The namespace can be any length and represent anything, does not have to be user specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6006e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f66c7",
   "metadata": {},
   "source": [
    "We use the `store.put` method to save memories to our namespace in the store. When we do this, we specify the namespace, as defined above, and a key-value pair for the memory: the key is simply a unique identifier for the memory (`memory_id`) and the value (a dictionary) is the memory itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb239142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e51843aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['1', 'memories'], key='c14d3e9f-f7bd-4cb4-9b78-95b17c2894a7', value={'food_preference': 'I like pizza'}, created_at='2025-11-04T08:45:21.491497+00:00', updated_at='2025-11-04T08:45:21.491502+00:00', score=None)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_memory_store.search(namespace_for_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb88e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': 'c14d3e9f-f7bd-4cb4-9b78-95b17c2894a7',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-11-04T08:45:21.491497+00:00',\n",
       " 'updated_at': '2025-11-04T08:45:21.491502+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_memory_store.search(namespace_for_memory)[-1].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477afa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b02d623",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439da199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d034ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a00a6510",
   "metadata": {},
   "source": [
    "## Using in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87ff97",
   "metadata": {},
   "source": [
    "We compile the graph with both the checkpointer and the `in_memory_store` as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b113638",
   "metadata": {},
   "source": [
    "```python\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# We need this because we want to enable threads (conversations)\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# ... Define the graph ...\n",
    "\n",
    "# Compile the graph with the checkpointer and store\n",
    "graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741e44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eab4703",
   "metadata": {},
   "source": [
    "We can access the `in_memory_store` and the `user_id` in any node by passing `store: BaseStore` and `config: RunnableConfig` as node arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa573eb",
   "metadata": {},
   "source": [
    "```Python\n",
    "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"memories\")\n",
    "\n",
    "    # ... Analyze conversation and create a new memory\n",
    "\n",
    "    # Create a new memory ID\n",
    "    memory_id = str(uuid.uuid4())\n",
    "\n",
    "    # We create a new memory\n",
    "    store.put(namespace, memory_id, {\"memory\": memory})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22201540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dafed29",
   "metadata": {},
   "source": [
    "We can access the memories and use them in our model call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d742849",
   "metadata": {},
   "source": [
    "```Python\n",
    "def call_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"memories\")\n",
    "\n",
    "    # Search based on the most recent message\n",
    "    memories = store.search(\n",
    "        namespace,\n",
    "        query=state[\"messages\"][-1].content,\n",
    "        limit=3\n",
    "    )\n",
    "    info = \"\\n\".join([d.value[\"memory\"] for d in memories])\n",
    "\n",
    "    # ... Use memories in the model call\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2cef96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b020c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5683346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1393e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287d696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
