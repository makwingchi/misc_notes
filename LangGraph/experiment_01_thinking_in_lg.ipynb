{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4df92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85171863",
   "metadata": {},
   "source": [
    "> https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ae9b8",
   "metadata": {},
   "source": [
    "**Build a customer support email agent**\n",
    "\n",
    "The agent should:\n",
    "- Read incoming customer emails\n",
    "- Classify them by urgency and topic\n",
    "- Search relevant documentation to answer questions\n",
    "- Draft appropriate responses\n",
    "- Escalate complex issues to human agents\n",
    "- Schedule follow-ups when needed\n",
    "\n",
    "Example scenarios to handle:\n",
    "1. Simple product question: “How do I reset my password?”\n",
    "2. Bug report: “The export feature crashes when I select PDF format”\n",
    "3. Urgent billing issue: “I was charged twice for my subscription!”\n",
    "4. Feature request: “Can you add dark mode to the mobile app?”\n",
    "5. Complex technical issue: “Our API integration fails intermittently with 504 errors”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a06ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e62de93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96205b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46fb82c5",
   "metadata": {},
   "source": [
    "# Step 1: Map out your workflow as discrete steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4328b",
   "metadata": {},
   "source": [
    "1. Read Email: Extract and parse the email content\n",
    "2. Classify Intent: Use an LLM to categorize urgency and topic, then route to appropriate action\n",
    "3. Doc Search: Query your knowledge base for relevant information\n",
    "4. Bug Track: Create or update issue in tracking system\n",
    "5. Draft Reply: Generate an appropriate response\n",
    "6. Human Review: Escalate to human agent for approval or handling\n",
    "7. Send Reply: Dispatch the email response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d3cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa9873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3488196",
   "metadata": {},
   "source": [
    "# Step 2: Identify what each step needs to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508ef5a",
   "metadata": {},
   "source": [
    "For each node in your graph, determine what type of operation it represents and what context it needs to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0e17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f9974d",
   "metadata": {},
   "source": [
    "# Step 3: Design your state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569db72",
   "metadata": {},
   "source": [
    "State is the shared memory accessible to all nodes in your agent. Think of it as the notebook your agent uses to keep track of everything it learns and decides as it works through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504101a4",
   "metadata": {},
   "source": [
    "## What belongs in state?\n",
    "\n",
    "- Include in State\n",
    "    - Does it need to persist across steps? If yes, it goes in state.\n",
    "- Don't Store\n",
    "    - Can you derive it from other data? If yes, compute it when needed instead of storing it in state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f6fe9",
   "metadata": {},
   "source": [
    "For our email agent, we need to track:\n",
    "- The original email and sender info (can’t reconstruct these)\n",
    "- Classification results (needed by multiple downstream nodes)\n",
    "- Search results and customer data (expensive to re-fetch)\n",
    "- The draft response (needs to persist through review)\n",
    "- Execution metadata (for debugging and recovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa786df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9deeb459",
   "metadata": {},
   "source": [
    "## Keep state raw, format prompts on-demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dc625",
   "metadata": {},
   "source": [
    "> A key principle: your state should store raw data, not formatted text. Format prompts inside nodes when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c0a0f",
   "metadata": {},
   "source": [
    "This separation means:\n",
    "- Different nodes can format the same data differently for their needs\n",
    "- You can change prompt templates without modifying your state schema\n",
    "- Debugging is clearer - you see exactly what data each node received\n",
    "- Your agent can evolve without breaking existing state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ade55cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Define the structure for email classification\n",
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str\n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Raw search/API results\n",
    "    search_results: list[str] | None  # List of raw document chunks\n",
    "    customer_history: dict | None  # Raw customer data from CRM\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n",
    "    messages: list[str] | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fa7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b32edba9",
   "metadata": {},
   "source": [
    "# Step 4: Build your nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3a3b4",
   "metadata": {},
   "source": [
    "Now we implement each step as a function. A node in LangGraph is just a Python function that takes the current state and returns updates to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58482b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f7fd974",
   "metadata": {},
   "source": [
    "## Read and classify nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d18296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command, RetryPolicy\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\")\n",
    "\n",
    "def read_email(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Extract and parse email content\"\"\"\n",
    "    # In production, this would connect to your email service\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]\n",
    "    }\n",
    "\n",
    "def classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n",
    "    \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n",
    "\n",
    "    # Create structured LLM that returns EmailClassification dict\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    # Format the prompt on-demand, not stored in state\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification including intent, urgency, topic, and summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get structured response directly as dict\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "\n",
    "    # Determine next node based on classification\n",
    "    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n",
    "        goto = \"human_review\"\n",
    "    elif classification['intent'] in ['question', 'feature']:\n",
    "        goto = \"search_documentation\"\n",
    "    elif classification['intent'] == 'bug':\n",
    "        goto = \"bug_tracking\"\n",
    "    else:\n",
    "        goto = \"draft_response\"\n",
    "\n",
    "    # Store classification as a single dict in state\n",
    "    return Command(\n",
    "        update={\"classification\": classification},\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffae7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d255045",
   "metadata": {},
   "source": [
    "## Search and tracking nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b523921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Search knowledge base for relevant information\"\"\"\n",
    "\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        # Implement your search logic here\n",
    "        # Store raw search results, not formatted text\n",
    "        search_results = [\n",
    "            \"Reset password via Settings > Security > Change Password\",\n",
    "            \"Password must be at least 12 characters\",\n",
    "            \"Include uppercase, lowercase, numbers, and symbols\"\n",
    "        ]\n",
    "    except SearchAPIError as e:\n",
    "        # For recoverable search errors, store error and continue\n",
    "        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n",
    "\n",
    "    return Command(\n",
    "        update={\"search_results\": search_results},  # Store raw results or error\n",
    "        goto=\"draft_response\"\n",
    "    )\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Create or update bug tracking ticket\"\"\"\n",
    "\n",
    "    # Create ticket in your bug tracking system\n",
    "    ticket_id = \"BUG-12345\"  # Would be created via API\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n",
    "            \"current_step\": \"bug_tracked\"\n",
    "        },\n",
    "        goto=\"draft_response\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516993c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd27f53a",
   "metadata": {},
   "source": [
    "## Response nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d793642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    \"\"\"Generate response using context and route based on quality\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # Format context from raw state data on-demand\n",
    "    context_sections = []\n",
    "\n",
    "    if state.get('search_results'):\n",
    "        # Format search results for the prompt\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "\n",
    "    if state.get('customer_history'):\n",
    "        # Format customer data for the prompt\n",
    "        context_sections.append(f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\")\n",
    "\n",
    "    # Build the prompt with formatted context\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    {state['email_content']}\n",
    "\n",
    "    Email intent: {classification.get('intent', 'unknown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "\n",
    "    {chr(10).join(context_sections)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(draft_prompt)\n",
    "\n",
    "    # Determine if human review needed based on urgency and intent\n",
    "    needs_review = (\n",
    "        classification.get('urgency') in ['high', 'critical'] or\n",
    "        classification.get('intent') == 'complex'\n",
    "    )\n",
    "\n",
    "    # Route to appropriate next node\n",
    "    goto = \"human_review\" if needs_review else \"send_reply\"\n",
    "\n",
    "    return Command(\n",
    "        update={\"draft_response\": response.content},  # Store only the raw response\n",
    "        goto=goto\n",
    "    )\n",
    "\n",
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    \"\"\"Pause for human review using interrupt and route based on decision\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # interrupt() must come first - any code before it will re-run on resume\n",
    "    human_decision = interrupt({\n",
    "        \"email_id\": state.get('email_id',''),\n",
    "        \"original_email\": state.get('email_content',''),\n",
    "        \"draft_response\": state.get('draft_response',''),\n",
    "        \"urgency\": classification.get('urgency'),\n",
    "        \"intent\": classification.get('intent'),\n",
    "        \"action\": \"Please review and approve/edit this response\"\n",
    "    })\n",
    "\n",
    "    # Now process the human's decision\n",
    "    if human_decision.get(\"approved\"):\n",
    "        return Command(\n",
    "            update={\"draft_response\": human_decision.get(\"edited_response\", state.get('draft_response',''))},\n",
    "            goto=\"send_reply\"\n",
    "        )\n",
    "    else:\n",
    "        # Rejection means human will handle directly\n",
    "        return Command(update={}, goto=END)\n",
    "\n",
    "def send_reply(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Send the email response\"\"\"\n",
    "    # Integrate with email service\n",
    "    print(f\"Sending reply: {state['draft_response'][:100]}...\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99657408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3c5ca2c",
   "metadata": {},
   "source": [
    "# Step 5: Wire it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca0d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(EmailAgentState)\n",
    "\n",
    "# Add nodes with appropriate error handling\n",
    "workflow.add_node(\"read_email\", read_email)\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "\n",
    "# Add retry policy for nodes that might have transient failures\n",
    "workflow.add_node(\n",
    "    \"search_documentation\",\n",
    "    search_documentation,\n",
    "    retry_policy=RetryPolicy(max_attempts=3)\n",
    ")\n",
    "workflow.add_node(\"bug_tracking\", bug_tracking)\n",
    "workflow.add_node(\"draft_response\", draft_response)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "workflow.add_node(\"send_reply\", send_reply)\n",
    "\n",
    "# Add only the essential edges\n",
    "workflow.add_edge(START, \"read_email\")\n",
    "workflow.add_edge(\"read_email\", \"classify_intent\")\n",
    "workflow.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence, in case run graph with Local_Server --> Please compile without checkpointer\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f9cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445a3965",
   "metadata": {},
   "source": [
    "## Test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3434cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft ready for review: ...\n",
      "Sending reply: We sincerely apologize for the double charge. I've initiated an immediate refund....\n",
      "Email sent successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test with an urgent billing issue\n",
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\",\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# Run with a thread_id for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_456\"}}\n",
    "result = app.invoke(initial_state, config)\n",
    "# The graph will pause at human_review\n",
    "print(f\"Draft ready for review: {result['__interrupt__'][0].value['draft_response']}...\")\n",
    "\n",
    "# When ready, provide human input to resume\n",
    "from langgraph.types import Command\n",
    "\n",
    "human_response = Command(\n",
    "    resume={\n",
    "        \"approved\": True,\n",
    "        \"edited_response\": \"We sincerely apologize for the double charge. I've initiated an immediate refund.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resume execution\n",
    "final_result = app.invoke(human_response, config)\n",
    "print(f\"Email sent successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e07b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4f3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988470f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0601450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8b4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
