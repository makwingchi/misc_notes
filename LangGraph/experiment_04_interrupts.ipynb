{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5ddfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e2e1dda",
   "metadata": {},
   "source": [
    "> https://docs.langchain.com/oss/python/langgraph/interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef36029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2fae086",
   "metadata": {},
   "source": [
    "When an interrupt is triggered, LangGraph saves the graph state using its `persistence` layer and waits indefinitely until you resume execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aac60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4cbb657",
   "metadata": {},
   "source": [
    "# Pause using `interrupt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085ab10",
   "metadata": {},
   "source": [
    "To use interrupt, you need:\n",
    "1. A **checkpointer** to persist the graph state (use a durable checkpointer in production)\n",
    "2. A **thread ID** in your config so the runtime knows which state to resume from\n",
    "3. To call `interrupt()` where you want to pause (payload must be JSON-serializable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc110b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e312000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    approved: bool\n",
    "\n",
    "\n",
    "def placeholder_node(state: State):\n",
    "    print(f\"placeholder: {state}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def approval_node(state: State):\n",
    "    # Pause and ask for approval\n",
    "    approved = interrupt(\"Do you approve this action?\")\n",
    "    print(approved)\n",
    "\n",
    "    # When you resume, Command(resume=...) returns that value here\n",
    "    return {\"approved\": approved}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30214974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1081606",
   "metadata": {},
   "source": [
    "When you call interrupt, hereâ€™s what happens:\n",
    "1. **Graph execution gets suspended** at the exact point where `interrupt` is called\n",
    "2. **State is saved** using the checkpointer so execution can be resumed later, In production, this should be a persistent checkpointer (e.g. backed by a database)\n",
    "3. **Value is returned** to the caller under `__interrupt__`; it can be any JSON-serializable value (string, object, array, etc.)\n",
    "4. **Graph waits indefinitely** until you resume execution with a response\n",
    "5. **Response is passed back** into the node when you resume, becoming the return value of the `interrupt()` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a04913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c3d0356",
   "metadata": {},
   "source": [
    "# Resuming interrupts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffce4b",
   "metadata": {},
   "source": [
    "After an interrupt pauses execution, you resume the graph by invoking it again with a `Command` that contains the resume value. The resume value is passed back to the `interrupt` call, allowing the node to continue execution with the external input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7de7f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder: {}\n",
      "[Interrupt(value='Do you approve this action?', id='d4b0109ec7ac8304d215caa6570fe339')]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'approved': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "graph = (\n",
    "    StateGraph(State)\n",
    "    .add_node(placeholder_node)\n",
    "    .add_node(approval_node)\n",
    "    .add_edge(START, \"placeholder_node\")\n",
    "    .add_edge(\"placeholder_node\", \"approval_node\")\n",
    "    .add_edge(\"approval_node\", END)\n",
    "    .compile(checkpointer=InMemorySaver())\n",
    ")\n",
    "\n",
    "# Initial run - hits the interrupt and pauses\n",
    "# thread_id is the persistent pointer (stores a stable ID in production)\n",
    "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "result = graph.invoke({\"input\": \"data\"}, config=config)\n",
    "\n",
    "# Check what was interrupted\n",
    "# __interrupt__ contains the payload that was passed to interrupt()\n",
    "print(result[\"__interrupt__\"])\n",
    "# > [Interrupt(value='Do you approve this action?')]\n",
    "\n",
    "# Resume with the human's response\n",
    "# The resume payload becomes the return value of interrupt() inside the node\n",
    "graph.invoke(Command(resume=True), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4b96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f2abfb",
   "metadata": {},
   "source": [
    "Key points about resuming:\n",
    "- You must use the **same thread ID** when resuming that was used when the interrupt occurred\n",
    "- The value passed to `Command(resume=...)` becomes the return value of the `interrupt` call\n",
    "- The node restarts from the beginning of the node where the `interrupt` was called when resumed, so any code before the `interrupt` runs again\n",
    "- You can pass any JSON-serializable value as the resume value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59aeaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51badde7",
   "metadata": {},
   "source": [
    "# Common patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0570ac5e",
   "metadata": {},
   "source": [
    "## Approve or reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc7564ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value={'question': 'Approve this action?', 'details': 'Transfer $500'}, id='7bed1482ac30b0d46898ef7bc1fe934e')]\n",
      "in proceed_node, state={'action_details': 'Transfer $500', 'status': 'approved'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class ApprovalState(TypedDict):\n",
    "    action_details: str\n",
    "    status: Optional[Literal[\"pending\", \"approved\", \"rejected\"]]\n",
    "\n",
    "\n",
    "def approval_node(state: ApprovalState) -> Command[Literal[\"proceed\", \"cancel\"]]:\n",
    "    # Expose details so the caller can render them in a UI\n",
    "    decision = interrupt({\n",
    "        \"question\": \"Approve this action?\",\n",
    "        \"details\": state[\"action_details\"],\n",
    "    })\n",
    "\n",
    "    # Route to the appropriate node after resume\n",
    "    return Command(goto=\"proceed\" if decision else \"cancel\")\n",
    "\n",
    "\n",
    "def proceed_node(state: ApprovalState):\n",
    "    state[\"status\"] = \"approved\"\n",
    "    return {\"status\": f\"in proceed_node, state={state}\"}\n",
    "\n",
    "\n",
    "def cancel_node(state: ApprovalState):\n",
    "    state[\"status\"] = \"rejected\"\n",
    "    return {\"status\": f\"in cancel_node, state={state}\"}\n",
    "\n",
    "\n",
    "builder = StateGraph(ApprovalState)\n",
    "builder.add_node(\"approval\", approval_node)\n",
    "builder.add_node(\"proceed\", proceed_node)\n",
    "builder.add_node(\"cancel\", cancel_node)\n",
    "builder.add_edge(START, \"approval\")\n",
    "builder.add_edge(\"proceed\", END)\n",
    "builder.add_edge(\"cancel\", END)\n",
    "\n",
    "# Use a more durable checkpointer in production\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-123\"}}\n",
    "initial = graph.invoke(\n",
    "    {\"action_details\": \"Transfer $500\", \"status\": \"pending\"},\n",
    "    config=config,\n",
    ")\n",
    "print(initial[\"__interrupt__\"])  # -> [Interrupt(value={'question': ..., 'details': ...})]\n",
    "\n",
    "# Resume with the decision; True routes to proceed, False to cancel\n",
    "resumed = graph.invoke(Command(resume=True), config=config)\n",
    "print(resumed[\"status\"])  # -> \"approved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6749a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22ce894b",
   "metadata": {},
   "source": [
    "## Review and edit state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf82d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value={'instruction': 'Review and edit this content', 'content': 'Initial draft'}, id='b65781a10b98c756b14a6667fb4eeb5c')]\n",
      "Improved draft after review\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class ReviewState(TypedDict):\n",
    "    generated_text: str\n",
    "\n",
    "\n",
    "def review_node(state: ReviewState):\n",
    "    # Ask a reviewer to edit the generated content\n",
    "    updated = interrupt({\n",
    "        \"instruction\": \"Review and edit this content\",\n",
    "        \"content\": state[\"generated_text\"],\n",
    "    })\n",
    "    return {\"generated_text\": updated}\n",
    "\n",
    "\n",
    "builder = StateGraph(ReviewState)\n",
    "builder.add_node(\"review\", review_node)\n",
    "builder.add_edge(START, \"review\")\n",
    "builder.add_edge(\"review\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"review-42\"}}\n",
    "initial = graph.invoke({\"generated_text\": \"Initial draft\"}, config=config)\n",
    "print(initial[\"__interrupt__\"])  # -> [Interrupt(value={'instruction': ..., 'content': ...})]\n",
    "\n",
    "# Resume with the edited text from the reviewer\n",
    "final_state = graph.invoke(\n",
    "    Command(resume=\"Improved draft after review\"),\n",
    "    config=config,\n",
    ")\n",
    "print(final_state[\"generated_text\"])  # -> \"Improved draft after review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fca597c",
   "metadata": {},
   "source": [
    "# Interrupts in tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: list[dict]\n",
    "\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str):\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "    # Pause before sending; payload surfaces in result[\"__interrupt__\"]\n",
    "    response = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Approve sending this email?\",\n",
    "    })\n",
    "\n",
    "    if response.get(\"action\") == \"approve\":\n",
    "        final_to = response.get(\"to\", to)\n",
    "        final_subject = response.get(\"subject\", subject)\n",
    "        final_body = response.get(\"body\", body)\n",
    "\n",
    "        # Actually send the email (your implementation here)\n",
    "        print(f\"[send_email] to={final_to} subject={final_subject} body={final_body}\")\n",
    "        return f\"Email sent to {final_to}\"\n",
    "\n",
    "    return \"Email cancelled by user\"\n",
    "\n",
    "\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\").bind_tools([send_email])\n",
    "\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    # LLM may decide to call the tool; interrupt pauses before sending\n",
    "    result = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": state[\"messages\"] + [result]}\n",
    "\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"agent\", agent_node)\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_edge(\"agent\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"email-workflow\"}}\n",
    "initial = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"\"\"to: alice@example.com\n",
    "                subject: about our meeting\n",
    "                body: Dear Alice, \\nI'm sorry to tell you that I just caught a fever yesterday. Could you please reschedule the meeting to next Monday?\\nBest Regards,\\nJohn\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(initial[\"__interrupt__\"])  # -> [Interrupt(value={'action': 'send_email', ...})]\n",
    "\n",
    "# Resume with approval and optionally edited arguments\n",
    "resumed = graph.invoke(\n",
    "    Command(resume={\"action\": \"approve\", \"subject\": \"Updated subject\"}),\n",
    "    config=config,\n",
    ")\n",
    "print(resumed[\"messages\"][-1])  # -> Tool result returned by send_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b3cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5bee08",
   "metadata": {},
   "source": [
    "## Validating human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92a5abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value='What is your age?', id='a8c352a2d708837b9b22eed076b9b9aa')]\n",
      "[Interrupt(value=\"'thirty' is not a valid age. Please enter a positive number.\", id='a8c352a2d708837b9b22eed076b9b9aa')]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class FormState(TypedDict):\n",
    "    age: int | None\n",
    "\n",
    "\n",
    "def get_age_node(state: FormState):\n",
    "    prompt = \"What is your age?\"\n",
    "\n",
    "    while True:\n",
    "        answer = interrupt(prompt)  # payload surfaces in result[\"__interrupt__\"]\n",
    "\n",
    "        if isinstance(answer, int) and answer > 0:\n",
    "            return {\"age\": answer}\n",
    "\n",
    "        prompt = f\"'{answer}' is not a valid age. Please enter a positive number.\"\n",
    "\n",
    "\n",
    "builder = StateGraph(FormState)\n",
    "builder.add_node(\"collect_age\", get_age_node)\n",
    "builder.add_edge(START, \"collect_age\")\n",
    "builder.add_edge(\"collect_age\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"form-1\"}}\n",
    "first = graph.invoke({\"age\": None}, config=config)\n",
    "print(first[\"__interrupt__\"])  # -> [Interrupt(value='What is your age?', ...)]\n",
    "\n",
    "# Provide invalid data; the node re-prompts\n",
    "retry = graph.invoke(Command(resume=\"thirty\"), config=config)\n",
    "print(retry[\"__interrupt__\"])  # -> [Interrupt(value=\"'thirty' is not a valid age...\", ...)]\n",
    "\n",
    "# Provide valid data; loop exits and state updates\n",
    "final = graph.invoke(Command(resume=30), config=config)\n",
    "print(final[\"age\"])  # -> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c879d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe87daa",
   "metadata": {},
   "source": [
    "# Rules of interrupts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53b5da",
   "metadata": {},
   "source": [
    "## Do not wrap `interrupt` calls in try/except"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f3e47",
   "metadata": {},
   "source": [
    "The way that `interrupt` pauses execution at the point of the call is by throwing a special exception. If you wrap the `interrupt` call in a try/except block, you will catch this exception and the interrupt will not be passed back to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ba3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd8a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b716c299",
   "metadata": {},
   "source": [
    "## Do not reorder `interrupt` calls within a node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7d139",
   "metadata": {},
   "source": [
    "- âœ… Keep interrupt calls consistent across node executions\n",
    "- ðŸ”´ Do not conditionally skip interrupt calls within a node\n",
    "- ðŸ”´ Do not loop interrupt calls using logic that isnâ€™t deterministic across executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5294d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e60c14e",
   "metadata": {},
   "source": [
    "## Do not return complex values in `interrupt` calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e18d13",
   "metadata": {},
   "source": [
    "Depending on which checkpointer is used, complex values may not be serializable (e.g. you canâ€™t serialize a function). To make your graphs adaptable to any deployment, itâ€™s best practice to only use values that can be reasonably serialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57785614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bcb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa1077e",
   "metadata": {},
   "source": [
    "## Side effects called before `interrupt` must be idempotent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316ca5c",
   "metadata": {},
   "source": [
    "Because interrupts work by re-running the nodes they were called from, side effects called before `interrupt` should (ideally) be idempotent. For context, idempotency means that the same operation can be applied multiple times without changing the result beyond the initial execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed03c53",
   "metadata": {},
   "source": [
    "As an example, you might have an API call to update a record inside of a node. If `interrupt` is called after that call is made, it will be re-run multiple times when the node is resumed, potentially overwriting the initial update or creating duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08baa1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7b161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4a9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
